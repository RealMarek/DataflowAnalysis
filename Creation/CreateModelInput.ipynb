{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outgoing_df = pd.read_csv(\"../Data/Köln/importantStructureOutgoing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50 Cent</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaron Lebedeff</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Act Up</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Al Harewood</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexander Jackson Davis</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Werner Janssen (Komponist)</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Westminster Kennel Club Dog Show</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>William Beach Lawrence</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>William Safire</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Young Concert Artists</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  link  type\n",
       "base                                        \n",
       "50 Cent                             29    29\n",
       "Aaron Lebedeff                      29    29\n",
       "Act Up                              28    28\n",
       "Al Harewood                         30    30\n",
       "Alexander Jackson Davis             26    26\n",
       "...                                ...   ...\n",
       "Werner Janssen (Komponist)          29    29\n",
       "Westminster Kennel Club Dog Show    28    28\n",
       "William Beach Lawrence              29    29\n",
       "William Safire                      30    30\n",
       "Young Concert Artists               30    30\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outgoing_df.groupby(\"base\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49656</th>\n",
       "      <td>Krieg von Castellammare</td>\n",
       "      <td>2023092500</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53038</th>\n",
       "      <td>Bonnie Bedelia</td>\n",
       "      <td>2023070600</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53055</th>\n",
       "      <td>Bonnie Bedelia</td>\n",
       "      <td>2023072300</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53058</th>\n",
       "      <td>Bonnie Bedelia</td>\n",
       "      <td>2023072600</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53062</th>\n",
       "      <td>Bonnie Bedelia</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180048</th>\n",
       "      <td>John Barrett (Friseur)</td>\n",
       "      <td>2023082100</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180049</th>\n",
       "      <td>John Barrett (Friseur)</td>\n",
       "      <td>2023082200</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182507</th>\n",
       "      <td>Internationales Hot-Dog-Wettessen</td>\n",
       "      <td>2023070400</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182508</th>\n",
       "      <td>Internationales Hot-Dog-Wettessen</td>\n",
       "      <td>2023070500</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182509</th>\n",
       "      <td>Internationales Hot-Dog-Wettessen</td>\n",
       "      <td>2023070600</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     link        date  views\n",
       "49656             Krieg von Castellammare  2023092500    132\n",
       "53038                      Bonnie Bedelia  2023070600    112\n",
       "53055                      Bonnie Bedelia  2023072300    192\n",
       "53058                      Bonnie Bedelia  2023072600    185\n",
       "53062                      Bonnie Bedelia  2023073000    162\n",
       "...                                   ...         ...    ...\n",
       "180048             John Barrett (Friseur)  2023082100    214\n",
       "180049             John Barrett (Friseur)  2023082200    104\n",
       "182507  Internationales Hot-Dog-Wettessen  2023070400    271\n",
       "182508  Internationales Hot-Dog-Wettessen  2023070500    339\n",
       "182509  Internationales Hot-Dog-Wettessen  2023070600    117\n",
       "\n",
       "[397 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views_df = pd.read_csv(\"../Data/Köln/views.csv\")\n",
    "views_df[(views_df[\"views\"] > 100) & (views_df[\"link\"].isin(outgoing_df[\"base\"]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill all empty dates in view_df with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dates = views_df[views_df[\"link\"] == \"50 Cent\"][\"date\"]\n",
    "# for link in views_df[\"link\"]:\n",
    "#   merged = \n",
    "#filled_views_df = list(map(lambda link: pd.merge(views_df[views_df[\"link\"] == link], all_dates, how=\"right\", on=\"date\").fillna({\"link\": link, \"views\": 0}), list(views_df[\"link\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FIFA-Weltfußballer des Jahres</td>\n",
       "      <td>2023070100</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FIFA-Weltfußballer des Jahres</td>\n",
       "      <td>2023070200</td>\n",
       "      <td>871.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FIFA-Weltfußballer des Jahres</td>\n",
       "      <td>2023070300</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FIFA-Weltfußballer des Jahres</td>\n",
       "      <td>2023070400</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FIFA-Weltfußballer des Jahres</td>\n",
       "      <td>2023070500</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203572</th>\n",
       "      <td>COVID-19-Pandemie</td>\n",
       "      <td>2023092700</td>\n",
       "      <td>913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203573</th>\n",
       "      <td>COVID-19-Pandemie</td>\n",
       "      <td>2023092800</td>\n",
       "      <td>876.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203574</th>\n",
       "      <td>COVID-19-Pandemie</td>\n",
       "      <td>2023092900</td>\n",
       "      <td>811.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203575</th>\n",
       "      <td>COVID-19-Pandemie</td>\n",
       "      <td>2023093000</td>\n",
       "      <td>715.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203576</th>\n",
       "      <td>COVID-19-Pandemie</td>\n",
       "      <td>2023100100</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203577 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 link        date  views\n",
       "0       FIFA-Weltfußballer des Jahres  2023070100  270.0\n",
       "1       FIFA-Weltfußballer des Jahres  2023070200  871.0\n",
       "2       FIFA-Weltfußballer des Jahres  2023070300  232.0\n",
       "3       FIFA-Weltfußballer des Jahres  2023070400  215.0\n",
       "4       FIFA-Weltfußballer des Jahres  2023070500  198.0\n",
       "...                               ...         ...    ...\n",
       "203572              COVID-19-Pandemie  2023092700  913.0\n",
       "203573              COVID-19-Pandemie  2023092800  876.0\n",
       "203574              COVID-19-Pandemie  2023092900  811.0\n",
       "203575              COVID-19-Pandemie  2023093000  715.0\n",
       "203576              COVID-19-Pandemie  2023100100  800.0\n",
       "\n",
       "[203577 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_df = pd.read_csv(\"../Data/Köln/filled_views.csv\")\n",
    "filled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th>link</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Charlie Barnett (Komiker)</td>\n",
       "      <td>1954</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charlie Barnett (Komiker)</td>\n",
       "      <td>Komiker</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie Barnett (Komiker)</td>\n",
       "      <td>Afroamerikaner</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charlie Barnett (Komiker)</td>\n",
       "      <td>New York City</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charlie Barnett (Komiker)</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>Michael Blake (Musiker)</td>\n",
       "      <td>Lounge Lizards</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>Michael Blake (Musiker)</td>\n",
       "      <td>Billy Martin (Schlagzeuger)</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>Michael Blake (Musiker)</td>\n",
       "      <td>David Tronzo</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>Michael Blake (Musiker)</td>\n",
       "      <td>Klarinette</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>Michael Blake (Musiker)</td>\n",
       "      <td>1964</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2550 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           base                         link      type\n",
       "0     Charlie Barnett (Komiker)                         1954  outgoing\n",
       "1     Charlie Barnett (Komiker)                      Komiker  outgoing\n",
       "2     Charlie Barnett (Komiker)               Afroamerikaner  outgoing\n",
       "3     Charlie Barnett (Komiker)                New York City  outgoing\n",
       "4     Charlie Barnett (Komiker)                West Virginia  outgoing\n",
       "...                         ...                          ...       ...\n",
       "2545    Michael Blake (Musiker)               Lounge Lizards  outgoing\n",
       "2546    Michael Blake (Musiker)  Billy Martin (Schlagzeuger)  outgoing\n",
       "2547    Michael Blake (Musiker)                 David Tronzo  outgoing\n",
       "2548    Michael Blake (Musiker)                   Klarinette  outgoing\n",
       "2549    Michael Blake (Musiker)                         1964  outgoing\n",
       "\n",
       "[2550 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = pd.read_csv(\"../Data/Köln/importantStructureOutgoing.csv\")\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9300"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combination = filled_df.merge(links,on=\"link\",how=\"right\")\n",
    "ml_output = []\n",
    "ml_link = []\n",
    "for base in links[\"base\"].sort_values().unique():\n",
    "  ml_output += filled_df[filled_df[\"link\"] == base].sort_values(\"date\")[\"views\"].to_list()\n",
    "  ml_link += filled_df[filled_df[\"link\"] == base][\"link\"].to_list()\n",
    "len(ml_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for idx in range(0, len(ml_output)) :\n",
    "    if ml_output[idx] > 100:\n",
    "        res.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination = combination.sort_values([\"base\", \"date\"], ignore_index=True)\n",
    "ml_input = []\n",
    "for base in combination[\"base\"].unique():\n",
    "  for date in combination[\"date\"].unique():\n",
    "    ml_input.append(combination[(combination[\"base\"] == base) & (combination[\"date\"] == date)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "ml_input[2][\"date\"]\n",
    "\n",
    "timestamp = 2023070100\n",
    "datetime = pd.to_datetime(timestamp, format='%Y%m%d%H')\n",
    "\n",
    "print(datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_input_value = [e[\"views\"].tolist() for e in ml_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>views</th>\n",
       "      <th>base</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>New York City</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>Run-D.M.C.</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>150.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>Recording Industry Association of America</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>1975</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>51.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>Billboard Hot 100</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>115.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>Goldene Schallplatte</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>174.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>Vereinigte Staaten</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>4932.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>Deutsche Singlecharts</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>246.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>Präsidentschaftswahl in den Vereinigten Staate...</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>248.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>Candy Shop</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>Power of the Dollar</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>Schauspieler</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>Dr. Dre</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>752.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>Queens</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>128.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>Shady Records</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>41.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>The Game (Rapper)</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>81.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>Get Rich or Die Tryin’ (Album)</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>Columbia Records</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>78.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>Springfield (Massachusetts)</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Guess Who’s Back?</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>The Massacre</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>6. Juli</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>Eminem</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>2817.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>Songwriting</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>69.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>Get Rich or Die Tryin’ (Film)</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>996.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>Aftermath Entertainment</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>69.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>Rap</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>203.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>Jam Master Jay</td>\n",
       "      <td>2023073000</td>\n",
       "      <td>69.0</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>outgoing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  link        date   views  \\\n",
       "841                                      New York City  2023073000  1921.0   \n",
       "842                                         Run-D.M.C.  2023073000   150.0   \n",
       "843          Recording Industry Association of America  2023073000    33.0   \n",
       "844                                               1975  2023073000    51.0   \n",
       "845                                  Billboard Hot 100  2023073000   115.0   \n",
       "846                               Goldene Schallplatte  2023073000   174.0   \n",
       "847                                 Vereinigte Staaten  2023073000  4932.0   \n",
       "848                              Deutsche Singlecharts  2023073000   246.0   \n",
       "849  Präsidentschaftswahl in den Vereinigten Staate...  2023073000   248.0   \n",
       "850                                         Candy Shop  2023073000    26.0   \n",
       "851                                Power of the Dollar  2023073000     6.0   \n",
       "852                                       Schauspieler  2023073000  1160.0   \n",
       "853                                            Dr. Dre  2023073000   752.0   \n",
       "854                                             Queens  2023073000   128.0   \n",
       "855                                      Shady Records  2023073000    41.0   \n",
       "856                                  The Game (Rapper)  2023073000    81.0   \n",
       "857                     Get Rich or Die Tryin’ (Album)  2023073000    18.0   \n",
       "858                                   Columbia Records  2023073000    78.0   \n",
       "859                        Springfield (Massachusetts)  2023073000    20.0   \n",
       "860                                  Guess Who’s Back?  2023073000     0.0   \n",
       "861                                       The Massacre  2023073000     9.0   \n",
       "862                                            6. Juli  2023073000    20.0   \n",
       "863                                             Eminem  2023073000  2817.0   \n",
       "864                                        Songwriting  2023073000    69.0   \n",
       "865                      Get Rich or Die Tryin’ (Film)  2023073000    35.0   \n",
       "866                                       Donald Trump  2023073000   996.0   \n",
       "867                            Aftermath Entertainment  2023073000    69.0   \n",
       "868                                                Rap  2023073000   203.0   \n",
       "869                                     Jam Master Jay  2023073000    69.0   \n",
       "\n",
       "        base      type  \n",
       "841  50 Cent  outgoing  \n",
       "842  50 Cent  outgoing  \n",
       "843  50 Cent  outgoing  \n",
       "844  50 Cent  outgoing  \n",
       "845  50 Cent  outgoing  \n",
       "846  50 Cent  outgoing  \n",
       "847  50 Cent  outgoing  \n",
       "848  50 Cent  outgoing  \n",
       "849  50 Cent  outgoing  \n",
       "850  50 Cent  outgoing  \n",
       "851  50 Cent  outgoing  \n",
       "852  50 Cent  outgoing  \n",
       "853  50 Cent  outgoing  \n",
       "854  50 Cent  outgoing  \n",
       "855  50 Cent  outgoing  \n",
       "856  50 Cent  outgoing  \n",
       "857  50 Cent  outgoing  \n",
       "858  50 Cent  outgoing  \n",
       "859  50 Cent  outgoing  \n",
       "860  50 Cent  outgoing  \n",
       "861  50 Cent  outgoing  \n",
       "862  50 Cent  outgoing  \n",
       "863  50 Cent  outgoing  \n",
       "864  50 Cent  outgoing  \n",
       "865  50 Cent  outgoing  \n",
       "866  50 Cent  outgoing  \n",
       "867  50 Cent  outgoing  \n",
       "868  50 Cent  outgoing  \n",
       "869  50 Cent  outgoing  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_input[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1921.0,\n",
       " 150.0,\n",
       " 33.0,\n",
       " 51.0,\n",
       " 115.0,\n",
       " 174.0,\n",
       " 4932.0,\n",
       " 246.0,\n",
       " 248.0,\n",
       " 26.0,\n",
       " 6.0,\n",
       " 1160.0,\n",
       " 752.0,\n",
       " 128.0,\n",
       " 41.0,\n",
       " 81.0,\n",
       " 18.0,\n",
       " 78.0,\n",
       " 20.0,\n",
       " 0.0,\n",
       " 9.0,\n",
       " 20.0,\n",
       " 2817.0,\n",
       " 69.0,\n",
       " 35.0,\n",
       " 996.0,\n",
       " 69.0,\n",
       " 203.0,\n",
       " 69.0]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_input_value[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1556.0,\n",
       " 174.0,\n",
       " 22.0,\n",
       " 44.0,\n",
       " 108.0,\n",
       " 221.0,\n",
       " 4378.0,\n",
       " 228.0,\n",
       " 186.0,\n",
       " 37.0,\n",
       " 8.0,\n",
       " 1003.0,\n",
       " 522.0,\n",
       " 101.0,\n",
       " 22.0,\n",
       " 133.0,\n",
       " 40.0,\n",
       " 57.0,\n",
       " 36.0,\n",
       " 0.0,\n",
       " 15.0,\n",
       " 61.0,\n",
       " 1718.0,\n",
       " 89.0,\n",
       " 53.0,\n",
       " 989.0,\n",
       " 26.0,\n",
       " 238.0,\n",
       " 84.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "for i in range(len(ml_input_value)):\n",
    "  if len(ml_input_value[i]) < 30:\n",
    "    zero_list = list(np.zeros(30- len(ml_input_value[i])))\n",
    "    ml_input_value[i] = ml_input_value[i] + zero_list\n",
    "\n",
    "ml_input_value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [1556.0, 174.0, 22.0, 44.0, 108.0, 221.0, 4378...\n",
       "1       [1981.0, 159.0, 28.0, 70.0, 115.0, 179.0, 4792...\n",
       "2       [1800.0, 96.0, 19.0, 67.0, 79.0, 174.0, 4872.0...\n",
       "3       [1715.0, 119.0, 20.0, 76.0, 88.0, 182.0, 5710....\n",
       "4       [1776.0, 114.0, 39.0, 75.0, 107.0, 177.0, 4933...\n",
       "                              ...                        \n",
       "9295    [1954.0, 4.0, 2267.0, 167.0, 2.0, 2.0, 835.0, ...\n",
       "9296    [1861.0, 3.0, 2135.0, 155.0, 3.0, 2.0, 789.0, ...\n",
       "9297    [1993.0, 3.0, 2068.0, 151.0, 2.0, 1.0, 812.0, ...\n",
       "9298    [2257.0, 5.0, 1934.0, 85.0, 1.0, 1.0, 787.0, 6...\n",
       "9299    [2182.0, 9.0, 2334.0, 118.0, 6.0, 0.0, 1004.0,...\n",
       "Name: input, Length: 9300, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_csv = {\"input\":ml_input_value,\"output\":ml_output}\n",
    "save_as_file = pd.DataFrame(for_csv)\n",
    "save_as_file[\"input\"]\n",
    "# save_as_file.to_csv(\"../Data/Köln/ml_training_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9300, 30)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.predict(ml_input_value[7900:8000])\n",
    "np.shape(ml_input_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [ 13.   0.   0. ... 218.   1.  28.]\n",
      "Actual: [15.0, 0.0, 2.0, 1.0, 1.0, 0.0, 561.0, 0.0, 103.0, 49.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 606.0, 120.0, 0.0, 0.0, 524.0, 0.0, 28.0, 4.0, 164.0, 6.0, 0.0, 9.0, 0.0, 1.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 12.0, 21.0, 1.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 0.0, 3.0, 0.0, 1.0, 33.0, 0.0, 12.0, 0.0, 3.0, 3.0, 7.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 1.0, 16.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 27.0, 204.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 10.0, 1.0, 35.0, 2.0, 1.0, 18.0, 3.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 4.0, 6.0, 0.0, 64.0, 6.0, 6.0, 0.0, 0.0, 1.0, 119.0, 0.0, 13.0, 25.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 24.0, 139.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 7.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 3.0, 4.0, 2.0, 3.0, 162.0, 38.0, 0.0, 0.0, 0.0, 4.0, 1.0, 10.0, 0.0, 0.0, 27.0, 10.0, 0.0, 1.0, 58.0, 3.0, 4.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 762.0, 3.0, 0.0, 0.0, 1.0, 18.0, 55.0, 206.0, 3.0, 4.0, 0.0, 17.0, 0.0, 0.0, 0.0, 5.0, 3.0, 3.0, 0.0, 1.0, 34.0, 0.0, 2.0, 2.0, 0.0, 15.0, 1.0, 87.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 3.0, 192.0, 47.0, 1.0, 22.0, 1.0, 10.0, 0.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 603.0, 7.0, 3.0, 3.0, 2.0, 287.0, 61.0, 1.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 0.0, 0.0, 566.0, 0.0, 2.0, 358.0, 0.0, 3.0, 20.0, 0.0, 2.0, 5.0, 2.0, 2.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 7.0, 0.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 5.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 11.0, 6.0, 33.0, 6.0, 1.0, 0.0, 9.0, 2.0, 0.0, 15.0, 2.0, 4.0, 1.0, 464.0, 8.0, 1.0, 30.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 6.0, 3.0, 458.0, 0.0, 10.0, 1.0, 0.0, 6.0, 1.0, 0.0, 140.0, 0.0, 13.0, 3.0, 6.0, 0.0, 4.0, 1.0, 2.0, 34.0, 3.0, 10.0, 0.0, 1.0, 0.0, 55.0, 1.0, 0.0, 0.0, 4.0, 118.0, 3.0, 299.0, 0.0, 9.0, 3.0, 0.0, 4.0, 7.0, 1.0, 2.0, 2.0, 5.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 2.0, 0.0, 0.0, 3.0, 9.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 4.0, 5.0, 0.0, 1.0, 477.0, 0.0, 8.0, 1.0, 2.0, 3.0, 0.0, 0.0, 3.0, 0.0, 3.0, 6.0, 1.0, 0.0, 0.0, 77.0, 0.0, 0.0, 0.0, 5.0, 448.0, 0.0, 0.0, 11.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 12.0, 6.0, 0.0, 6.0, 5.0, 0.0, 8.0, 20.0, 1.0, 1.0, 60.0, 12.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 16.0, 1.0, 1.0, 1.0, 1.0, 49.0, 0.0, 0.0, 0.0, 576.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 2.0, 3.0, 11.0, 1.0, 6.0, 1.0, 234.0, 3.0, 4.0, 0.0, 0.0, 6.0, 4.0, 0.0, 25.0, 0.0, 5.0, 48.0, 6.0, 624.0, 0.0, 1.0, 113.0, 0.0, 3.0, 5.0, 1.0, 3.0, 2.0, 4.0, 0.0, 0.0, 1.0, 21.0, 1.0, 0.0, 8.0, 3.0, 15.0, 0.0, 4.0, 0.0, 10.0, 0.0, 30.0, 2.0, 0.0, 249.0, 262.0, 86.0, 4.0, 2.0, 0.0, 6.0, 1.0, 1.0, 0.0, 2.0, 289.0, 20.0, 0.0, 5.0, 0.0, 458.0, 0.0, 560.0, 2.0, 7.0, 6.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 1.0, 9.0, 0.0, 3.0, 7.0, 0.0, 1.0, 1.0, 2.0, 119.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 33.0, 57.0, 3.0, 3.0, 2.0, 1.0, 10.0, 4.0, 5.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 6.0, 0.0, 1.0, 0.0, 16.0, 0.0, 86.0, 0.0, 0.0, 1.0, 36.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 4.0, 0.0, 0.0, 6.0, 1.0, 19.0, 10.0, 0.0, 7.0, 6.0, 0.0, 5.0, 0.0, 0.0, 12.0, 493.0, 27.0, 1.0, 0.0, 104.0, 0.0, 3.0, 0.0, 13.0, 2.0, 2.0, 66.0, 0.0, 29.0, 1.0, 2.0, 0.0, 1.0, 5.0, 1.0, 1.0, 0.0, 26.0, 2.0, 0.0, 5.0, 1.0, 0.0, 0.0, 1.0, 0.0, 87.0, 2.0, 2.0, 4.0, 1.0, 0.0, 2.0, 4.0, 0.0, 18.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 310.0, 0.0, 3.0, 1.0, 2.0, 0.0, 3.0, 31.0, 2.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 15.0, 1.0, 20.0, 10.0, 0.0, 0.0, 1.0, 9.0, 0.0, 14.0, 0.0, 0.0, 2.0, 3.0, 0.0, 19.0, 19.0, 214.0, 2.0, 53.0, 3.0, 3.0, 1.0, 0.0, 2.0, 5.0, 2.0, 1.0, 4.0, 9.0, 3.0, 93.0, 1.0, 1.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 19.0, 4.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 16.0, 1.0, 72.0, 0.0, 0.0, 56.0, 1.0, 6.0, 1.0, 0.0, 11.0, 0.0, 1.0, 1.0, 9.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 5.0, 0.0, 1.0, 2.0, 73.0, 1.0, 1.0, 0.0, 56.0, 1.0, 2.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 19.0, 12.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 5.0, 51.0, 0.0, 3.0, 1.0, 4.0, 3.0, 17.0, 0.0, 34.0, 59.0, 2.0, 1.0, 4.0, 0.0, 30.0, 887.0, 5.0, 0.0, 0.0, 14.0, 1.0, 13.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 3.0, 4.0, 0.0, 0.0, 6.0, 1.0, 0.0, 3.0, 3.0, 1.0, 4.0, 1.0, 0.0, 0.0, 54.0, 1.0, 1.0, 0.0, 7.0, 13.0, 3.0, 240.0, 1.0, 0.0, 25.0, 1.0, 7.0, 0.0, 2.0, 5.0, 0.0, 0.0, 2.0, 7.0, 1.0, 41.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 536.0, 2.0, 1.0, 15.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 0.0, 81.0, 0.0, 5.0, 0.0, 3.0, 0.0, 6.0, 0.0, 0.0, 2.0, 17.0, 0.0, 1.0, 114.0, 4.0, 1.0, 76.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 43.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 19.0, 18.0, 1.0, 4.0, 13.0, 215.0, 9.0, 218.0, 0.0, 14.0, 0.0, 0.0, 1.0, 0.0, 1.0, 8.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 582.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 4.0, 0.0, 0.0, 12.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 10.0, 4.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 3.0, 2.0, 0.0, 0.0, 76.0, 0.0, 1.0, 2.0, 1.0, 10.0, 0.0, 1.0, 98.0, 29.0, 0.0, 3.0, 1.0, 1.0, 1.0, 16.0, 1.0, 0.0, 4.0, 1.0, 1.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 104.0, 0.0, 4.0, 3.0, 0.0, 5.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 35.0, 17.0, 0.0, 45.0, 1.0, 3.0, 0.0, 294.0, 0.0, 6.0, 0.0, 639.0, 0.0, 2.0, 9.0, 10.0, 0.0, 12.0, 9.0, 0.0, 0.0, 0.0, 0.0, 7.0, 1.0, 9.0, 2.0, 7.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 14.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 322.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 6.0, 3.0, 1.0, 0.0, 4.0, 0.0, 21.0, 0.0, 0.0, 6.0, 2.0, 0.0, 1.0, 4.0, 33.0, 4.0, 50.0, 1.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 27.0, 14.0, 0.0, 0.0, 0.0, 21.0, 1.0, 0.0, 198.0, 3.0, 0.0, 0.0, 3.0, 42.0, 0.0, 105.0, 0.0, 3.0, 3.0, 0.0, 0.0, 37.0, 13.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 26.0, 1.0, 2.0, 10.0, 4.0, 0.0, 1.0, 0.0, 1.0, 1.0, 17.0, 0.0, 2.0, 2.0, 11.0, 2.0, 5.0, 2.0, 0.0, 0.0, 12.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 10.0, 1.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 2.0, 573.0, 6.0, 2.0, 5.0, 13.0, 3.0, 0.0, 15.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 533.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 17.0, 2.0, 1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 0.0, 22.0, 3.0, 1.0, 12.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 0.0, 6.0, 0.0, 45.0, 0.0, 0.0, 0.0, 0.0, 6.0, 22.0, 5.0, 3.0, 0.0, 2.0, 2.0, 1.0, 0.0, 73.0, 591.0, 10.0, 0.0, 1.0, 4.0, 3.0, 0.0, 90.0, 92.0, 38.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 11.0, 360.0, 0.0, 1.0, 3.0, 0.0, 2.0, 11.0, 80.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 33.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 4.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 4.0, 0.0, 2.0, 97.0, 4.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 7.0, 3.0, 12.0, 267.0, 0.0, 1.0, 0.0, 2.0, 5.0, 1.0, 6.0, 1.0, 2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 110.0, 0.0, 1.0, 4.0, 0.0, 1.0, 3.0, 585.0, 0.0, 1.0, 0.0, 1.0, 1.0, 12.0, 3.0, 1.0, 0.0, 2.0, 4.0, 2.0, 0.0, 3.0, 0.0, 0.0, 6.0, 2.0, 0.0, 1.0, 31.0, 81.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 270.0, 4.0, 3.0, 0.0, 2.0, 1.0, 271.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 14.0, 3.0, 4.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 3.0, 1.0, 0.0, 11.0, 21.0, 1.0, 1.0, 0.0, 9.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 35.0, 1.0, 1.0, 1.0, 85.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 12.0, 0.0, 3.0, 5.0, 0.0, 3.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 10.0, 5.0, 3.0, 5.0, 0.0, 129.0, 6.0, 68.0, 3.0, 0.0, 11.0, 2.0, 0.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.0, 10.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 5.0, 0.0, 3.0, 0.0, 0.0, 114.0, 5.0, 3.0, 0.0, 1.0, 13.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 29.0, 7.0, 50.0, 19.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 15.0, 0.0, 0.0, 6.0, 2.0, 1.0, 0.0, 488.0, 7.0, 1.0, 1.0, 10.0, 0.0, 0.0, 0.0, 7.0, 14.0, 3.0, 5.0, 2.0, 1.0, 16.0, 0.0, 12.0, 12.0, 0.0, 66.0, 0.0, 3.0, 3.0, 2.0, 26.0, 0.0, 0.0, 5.0, 12.0, 0.0, 11.0, 4.0, 21.0, 1.0, 2.0, 639.0, 2.0, 4.0, 0.0, 3.0, 16.0, 2.0, 0.0, 3.0, 5.0, 1.0, 0.0, 4.0, 2.0, 7.0, 2.0, 1.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 176.0, 555.0, 6.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 32.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 7.0, 0.0, 3.0, 0.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 27.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 10.0, 0.0, 0.0, 1.0, 5.0, 6.0, 11.0, 3.0, 2.0, 6.0, 1.0, 5.0, 29.0, 22.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 14.0, 2.0, 13.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 45.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 4.0, 4.0, 2.0, 9.0, 0.0, 1.0, 1.0, 111.0, 2.0, 0.0, 24.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 4.0, 38.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 86.0, 2.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 32.0, 87.0, 0.0, 6.0, 3.0, 15.0, 287.0, 123.0, 8.0, 11.0, 4.0, 1.0, 2.0, 0.0, 2.0, 0.0, 56.0, 0.0, 0.0, 3.0, 469.0, 15.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 906.0, 3.0, 0.0, 3.0, 0.0, 3.0, 2.0, 14.0, 2.0, 1.0, 0.0, 0.0, 0.0, 12.0, 1.0, 1.0, 0.0, 10.0, 0.0, 1272.0, 6.0, 0.0, 4.0, 0.0, 1.0, 0.0, 34.0, 4.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 1.0, 5.0, 0.0, 185.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 0.0, 1.0, 219.0, 0.0, 66.0]\n",
      "Mean Absolute Error: 4.99247311827957\n",
      "Mean Squared Error: 411.505376344086\n",
      "Root Mean Squared Error: 20.285595291834206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(ml_input_value)\n",
    "y = ml_output\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# print the results\n",
    "print('Predicted:', y_pred)\n",
    "print('Actual:', y_test)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [ 11.   0.   0. ... 205.   0.  29.]\n",
      "Actual: [15.0, 0.0, 2.0, 1.0, 1.0, 0.0, 561.0, 0.0, 103.0, 49.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 606.0, 120.0, 0.0, 0.0, 524.0, 0.0, 28.0, 4.0, 164.0, 6.0, 0.0, 9.0, 0.0, 1.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 12.0, 21.0, 1.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 0.0, 3.0, 0.0, 1.0, 33.0, 0.0, 12.0, 0.0, 3.0, 3.0, 7.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 1.0, 16.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 27.0, 204.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 10.0, 1.0, 35.0, 2.0, 1.0, 18.0, 3.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 4.0, 6.0, 0.0, 64.0, 6.0, 6.0, 0.0, 0.0, 1.0, 119.0, 0.0, 13.0, 25.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 24.0, 139.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 7.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 3.0, 4.0, 2.0, 3.0, 162.0, 38.0, 0.0, 0.0, 0.0, 4.0, 1.0, 10.0, 0.0, 0.0, 27.0, 10.0, 0.0, 1.0, 58.0, 3.0, 4.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 762.0, 3.0, 0.0, 0.0, 1.0, 18.0, 55.0, 206.0, 3.0, 4.0, 0.0, 17.0, 0.0, 0.0, 0.0, 5.0, 3.0, 3.0, 0.0, 1.0, 34.0, 0.0, 2.0, 2.0, 0.0, 15.0, 1.0, 87.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 3.0, 192.0, 47.0, 1.0, 22.0, 1.0, 10.0, 0.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 603.0, 7.0, 3.0, 3.0, 2.0, 287.0, 61.0, 1.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 0.0, 0.0, 566.0, 0.0, 2.0, 358.0, 0.0, 3.0, 20.0, 0.0, 2.0, 5.0, 2.0, 2.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 7.0, 0.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 5.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 11.0, 6.0, 33.0, 6.0, 1.0, 0.0, 9.0, 2.0, 0.0, 15.0, 2.0, 4.0, 1.0, 464.0, 8.0, 1.0, 30.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 6.0, 3.0, 458.0, 0.0, 10.0, 1.0, 0.0, 6.0, 1.0, 0.0, 140.0, 0.0, 13.0, 3.0, 6.0, 0.0, 4.0, 1.0, 2.0, 34.0, 3.0, 10.0, 0.0, 1.0, 0.0, 55.0, 1.0, 0.0, 0.0, 4.0, 118.0, 3.0, 299.0, 0.0, 9.0, 3.0, 0.0, 4.0, 7.0, 1.0, 2.0, 2.0, 5.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 2.0, 0.0, 0.0, 3.0, 9.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 4.0, 5.0, 0.0, 1.0, 477.0, 0.0, 8.0, 1.0, 2.0, 3.0, 0.0, 0.0, 3.0, 0.0, 3.0, 6.0, 1.0, 0.0, 0.0, 77.0, 0.0, 0.0, 0.0, 5.0, 448.0, 0.0, 0.0, 11.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 12.0, 6.0, 0.0, 6.0, 5.0, 0.0, 8.0, 20.0, 1.0, 1.0, 60.0, 12.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 16.0, 1.0, 1.0, 1.0, 1.0, 49.0, 0.0, 0.0, 0.0, 576.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 2.0, 3.0, 11.0, 1.0, 6.0, 1.0, 234.0, 3.0, 4.0, 0.0, 0.0, 6.0, 4.0, 0.0, 25.0, 0.0, 5.0, 48.0, 6.0, 624.0, 0.0, 1.0, 113.0, 0.0, 3.0, 5.0, 1.0, 3.0, 2.0, 4.0, 0.0, 0.0, 1.0, 21.0, 1.0, 0.0, 8.0, 3.0, 15.0, 0.0, 4.0, 0.0, 10.0, 0.0, 30.0, 2.0, 0.0, 249.0, 262.0, 86.0, 4.0, 2.0, 0.0, 6.0, 1.0, 1.0, 0.0, 2.0, 289.0, 20.0, 0.0, 5.0, 0.0, 458.0, 0.0, 560.0, 2.0, 7.0, 6.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 1.0, 9.0, 0.0, 3.0, 7.0, 0.0, 1.0, 1.0, 2.0, 119.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 33.0, 57.0, 3.0, 3.0, 2.0, 1.0, 10.0, 4.0, 5.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 6.0, 0.0, 1.0, 0.0, 16.0, 0.0, 86.0, 0.0, 0.0, 1.0, 36.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 4.0, 0.0, 0.0, 6.0, 1.0, 19.0, 10.0, 0.0, 7.0, 6.0, 0.0, 5.0, 0.0, 0.0, 12.0, 493.0, 27.0, 1.0, 0.0, 104.0, 0.0, 3.0, 0.0, 13.0, 2.0, 2.0, 66.0, 0.0, 29.0, 1.0, 2.0, 0.0, 1.0, 5.0, 1.0, 1.0, 0.0, 26.0, 2.0, 0.0, 5.0, 1.0, 0.0, 0.0, 1.0, 0.0, 87.0, 2.0, 2.0, 4.0, 1.0, 0.0, 2.0, 4.0, 0.0, 18.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 310.0, 0.0, 3.0, 1.0, 2.0, 0.0, 3.0, 31.0, 2.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 15.0, 1.0, 20.0, 10.0, 0.0, 0.0, 1.0, 9.0, 0.0, 14.0, 0.0, 0.0, 2.0, 3.0, 0.0, 19.0, 19.0, 214.0, 2.0, 53.0, 3.0, 3.0, 1.0, 0.0, 2.0, 5.0, 2.0, 1.0, 4.0, 9.0, 3.0, 93.0, 1.0, 1.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 19.0, 4.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 16.0, 1.0, 72.0, 0.0, 0.0, 56.0, 1.0, 6.0, 1.0, 0.0, 11.0, 0.0, 1.0, 1.0, 9.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 5.0, 0.0, 1.0, 2.0, 73.0, 1.0, 1.0, 0.0, 56.0, 1.0, 2.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 19.0, 12.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 5.0, 51.0, 0.0, 3.0, 1.0, 4.0, 3.0, 17.0, 0.0, 34.0, 59.0, 2.0, 1.0, 4.0, 0.0, 30.0, 887.0, 5.0, 0.0, 0.0, 14.0, 1.0, 13.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 3.0, 4.0, 0.0, 0.0, 6.0, 1.0, 0.0, 3.0, 3.0, 1.0, 4.0, 1.0, 0.0, 0.0, 54.0, 1.0, 1.0, 0.0, 7.0, 13.0, 3.0, 240.0, 1.0, 0.0, 25.0, 1.0, 7.0, 0.0, 2.0, 5.0, 0.0, 0.0, 2.0, 7.0, 1.0, 41.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 536.0, 2.0, 1.0, 15.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 0.0, 81.0, 0.0, 5.0, 0.0, 3.0, 0.0, 6.0, 0.0, 0.0, 2.0, 17.0, 0.0, 1.0, 114.0, 4.0, 1.0, 76.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 43.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 19.0, 18.0, 1.0, 4.0, 13.0, 215.0, 9.0, 218.0, 0.0, 14.0, 0.0, 0.0, 1.0, 0.0, 1.0, 8.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 582.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 4.0, 0.0, 0.0, 12.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 10.0, 4.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 3.0, 2.0, 0.0, 0.0, 76.0, 0.0, 1.0, 2.0, 1.0, 10.0, 0.0, 1.0, 98.0, 29.0, 0.0, 3.0, 1.0, 1.0, 1.0, 16.0, 1.0, 0.0, 4.0, 1.0, 1.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 104.0, 0.0, 4.0, 3.0, 0.0, 5.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 35.0, 17.0, 0.0, 45.0, 1.0, 3.0, 0.0, 294.0, 0.0, 6.0, 0.0, 639.0, 0.0, 2.0, 9.0, 10.0, 0.0, 12.0, 9.0, 0.0, 0.0, 0.0, 0.0, 7.0, 1.0, 9.0, 2.0, 7.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 14.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 322.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 6.0, 3.0, 1.0, 0.0, 4.0, 0.0, 21.0, 0.0, 0.0, 6.0, 2.0, 0.0, 1.0, 4.0, 33.0, 4.0, 50.0, 1.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 27.0, 14.0, 0.0, 0.0, 0.0, 21.0, 1.0, 0.0, 198.0, 3.0, 0.0, 0.0, 3.0, 42.0, 0.0, 105.0, 0.0, 3.0, 3.0, 0.0, 0.0, 37.0, 13.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 26.0, 1.0, 2.0, 10.0, 4.0, 0.0, 1.0, 0.0, 1.0, 1.0, 17.0, 0.0, 2.0, 2.0, 11.0, 2.0, 5.0, 2.0, 0.0, 0.0, 12.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 10.0, 1.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 2.0, 573.0, 6.0, 2.0, 5.0, 13.0, 3.0, 0.0, 15.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 533.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 17.0, 2.0, 1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 0.0, 22.0, 3.0, 1.0, 12.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 0.0, 6.0, 0.0, 45.0, 0.0, 0.0, 0.0, 0.0, 6.0, 22.0, 5.0, 3.0, 0.0, 2.0, 2.0, 1.0, 0.0, 73.0, 591.0, 10.0, 0.0, 1.0, 4.0, 3.0, 0.0, 90.0, 92.0, 38.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 11.0, 360.0, 0.0, 1.0, 3.0, 0.0, 2.0, 11.0, 80.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 33.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 4.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 4.0, 0.0, 2.0, 97.0, 4.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 7.0, 3.0, 12.0, 267.0, 0.0, 1.0, 0.0, 2.0, 5.0, 1.0, 6.0, 1.0, 2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 110.0, 0.0, 1.0, 4.0, 0.0, 1.0, 3.0, 585.0, 0.0, 1.0, 0.0, 1.0, 1.0, 12.0, 3.0, 1.0, 0.0, 2.0, 4.0, 2.0, 0.0, 3.0, 0.0, 0.0, 6.0, 2.0, 0.0, 1.0, 31.0, 81.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 270.0, 4.0, 3.0, 0.0, 2.0, 1.0, 271.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 14.0, 3.0, 4.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 3.0, 1.0, 0.0, 11.0, 21.0, 1.0, 1.0, 0.0, 9.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 35.0, 1.0, 1.0, 1.0, 85.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 12.0, 0.0, 3.0, 5.0, 0.0, 3.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 10.0, 5.0, 3.0, 5.0, 0.0, 129.0, 6.0, 68.0, 3.0, 0.0, 11.0, 2.0, 0.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.0, 10.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 5.0, 0.0, 3.0, 0.0, 0.0, 114.0, 5.0, 3.0, 0.0, 1.0, 13.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 29.0, 7.0, 50.0, 19.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 15.0, 0.0, 0.0, 6.0, 2.0, 1.0, 0.0, 488.0, 7.0, 1.0, 1.0, 10.0, 0.0, 0.0, 0.0, 7.0, 14.0, 3.0, 5.0, 2.0, 1.0, 16.0, 0.0, 12.0, 12.0, 0.0, 66.0, 0.0, 3.0, 3.0, 2.0, 26.0, 0.0, 0.0, 5.0, 12.0, 0.0, 11.0, 4.0, 21.0, 1.0, 2.0, 639.0, 2.0, 4.0, 0.0, 3.0, 16.0, 2.0, 0.0, 3.0, 5.0, 1.0, 0.0, 4.0, 2.0, 7.0, 2.0, 1.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 176.0, 555.0, 6.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 32.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 7.0, 0.0, 3.0, 0.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 27.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 10.0, 0.0, 0.0, 1.0, 5.0, 6.0, 11.0, 3.0, 2.0, 6.0, 1.0, 5.0, 29.0, 22.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 14.0, 2.0, 13.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 45.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 4.0, 4.0, 2.0, 9.0, 0.0, 1.0, 1.0, 111.0, 2.0, 0.0, 24.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 4.0, 38.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 86.0, 2.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 32.0, 87.0, 0.0, 6.0, 3.0, 15.0, 287.0, 123.0, 8.0, 11.0, 4.0, 1.0, 2.0, 0.0, 2.0, 0.0, 56.0, 0.0, 0.0, 3.0, 469.0, 15.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 906.0, 3.0, 0.0, 3.0, 0.0, 3.0, 2.0, 14.0, 2.0, 1.0, 0.0, 0.0, 0.0, 12.0, 1.0, 1.0, 0.0, 10.0, 0.0, 1272.0, 6.0, 0.0, 4.0, 0.0, 1.0, 0.0, 34.0, 4.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 1.0, 5.0, 0.0, 185.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 0.0, 1.0, 219.0, 0.0, 66.0]\n",
      "Mean Absolute Error: 5.645914327607876\n",
      "Mean Squared Error: 627.4839081792096\n",
      "Root Mean Squared Error: 25.049628903023883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(ml_input_value)\n",
    "y = ml_output\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "sel = SelectFromModel(model)\n",
    "X_trans = sel.fit_transform(X_train, y_train)\n",
    "\n",
    "model.fit(X_trans, y_train)\n",
    "\n",
    "X_test_trans = sel.transform(X_test)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test_trans)\n",
    "\n",
    "# print the results\n",
    "print('Predicted:', y_pred)\n",
    "print('Actual:', y_test)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [1.1040e+01 1.2000e-01 1.1600e+00 ... 1.9398e+02 1.1600e+00 4.5560e+01]\n",
      "Actual: [15.0, 0.0, 2.0, 1.0, 1.0, 0.0, 561.0, 0.0, 103.0, 49.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 606.0, 120.0, 0.0, 0.0, 524.0, 0.0, 28.0, 4.0, 164.0, 6.0, 0.0, 9.0, 0.0, 1.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 12.0, 21.0, 1.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 0.0, 3.0, 0.0, 1.0, 33.0, 0.0, 12.0, 0.0, 3.0, 3.0, 7.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 1.0, 16.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 27.0, 204.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 10.0, 1.0, 35.0, 2.0, 1.0, 18.0, 3.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 4.0, 6.0, 0.0, 64.0, 6.0, 6.0, 0.0, 0.0, 1.0, 119.0, 0.0, 13.0, 25.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 24.0, 139.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 7.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 3.0, 4.0, 2.0, 3.0, 162.0, 38.0, 0.0, 0.0, 0.0, 4.0, 1.0, 10.0, 0.0, 0.0, 27.0, 10.0, 0.0, 1.0, 58.0, 3.0, 4.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 762.0, 3.0, 0.0, 0.0, 1.0, 18.0, 55.0, 206.0, 3.0, 4.0, 0.0, 17.0, 0.0, 0.0, 0.0, 5.0, 3.0, 3.0, 0.0, 1.0, 34.0, 0.0, 2.0, 2.0, 0.0, 15.0, 1.0, 87.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 3.0, 192.0, 47.0, 1.0, 22.0, 1.0, 10.0, 0.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 603.0, 7.0, 3.0, 3.0, 2.0, 287.0, 61.0, 1.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 0.0, 0.0, 566.0, 0.0, 2.0, 358.0, 0.0, 3.0, 20.0, 0.0, 2.0, 5.0, 2.0, 2.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 7.0, 0.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 5.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 11.0, 6.0, 33.0, 6.0, 1.0, 0.0, 9.0, 2.0, 0.0, 15.0, 2.0, 4.0, 1.0, 464.0, 8.0, 1.0, 30.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 6.0, 3.0, 458.0, 0.0, 10.0, 1.0, 0.0, 6.0, 1.0, 0.0, 140.0, 0.0, 13.0, 3.0, 6.0, 0.0, 4.0, 1.0, 2.0, 34.0, 3.0, 10.0, 0.0, 1.0, 0.0, 55.0, 1.0, 0.0, 0.0, 4.0, 118.0, 3.0, 299.0, 0.0, 9.0, 3.0, 0.0, 4.0, 7.0, 1.0, 2.0, 2.0, 5.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 2.0, 0.0, 0.0, 3.0, 9.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 4.0, 5.0, 0.0, 1.0, 477.0, 0.0, 8.0, 1.0, 2.0, 3.0, 0.0, 0.0, 3.0, 0.0, 3.0, 6.0, 1.0, 0.0, 0.0, 77.0, 0.0, 0.0, 0.0, 5.0, 448.0, 0.0, 0.0, 11.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 12.0, 6.0, 0.0, 6.0, 5.0, 0.0, 8.0, 20.0, 1.0, 1.0, 60.0, 12.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 16.0, 1.0, 1.0, 1.0, 1.0, 49.0, 0.0, 0.0, 0.0, 576.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 2.0, 3.0, 11.0, 1.0, 6.0, 1.0, 234.0, 3.0, 4.0, 0.0, 0.0, 6.0, 4.0, 0.0, 25.0, 0.0, 5.0, 48.0, 6.0, 624.0, 0.0, 1.0, 113.0, 0.0, 3.0, 5.0, 1.0, 3.0, 2.0, 4.0, 0.0, 0.0, 1.0, 21.0, 1.0, 0.0, 8.0, 3.0, 15.0, 0.0, 4.0, 0.0, 10.0, 0.0, 30.0, 2.0, 0.0, 249.0, 262.0, 86.0, 4.0, 2.0, 0.0, 6.0, 1.0, 1.0, 0.0, 2.0, 289.0, 20.0, 0.0, 5.0, 0.0, 458.0, 0.0, 560.0, 2.0, 7.0, 6.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 1.0, 9.0, 0.0, 3.0, 7.0, 0.0, 1.0, 1.0, 2.0, 119.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 33.0, 57.0, 3.0, 3.0, 2.0, 1.0, 10.0, 4.0, 5.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 6.0, 0.0, 1.0, 0.0, 16.0, 0.0, 86.0, 0.0, 0.0, 1.0, 36.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 4.0, 0.0, 0.0, 6.0, 1.0, 19.0, 10.0, 0.0, 7.0, 6.0, 0.0, 5.0, 0.0, 0.0, 12.0, 493.0, 27.0, 1.0, 0.0, 104.0, 0.0, 3.0, 0.0, 13.0, 2.0, 2.0, 66.0, 0.0, 29.0, 1.0, 2.0, 0.0, 1.0, 5.0, 1.0, 1.0, 0.0, 26.0, 2.0, 0.0, 5.0, 1.0, 0.0, 0.0, 1.0, 0.0, 87.0, 2.0, 2.0, 4.0, 1.0, 0.0, 2.0, 4.0, 0.0, 18.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 310.0, 0.0, 3.0, 1.0, 2.0, 0.0, 3.0, 31.0, 2.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 15.0, 1.0, 20.0, 10.0, 0.0, 0.0, 1.0, 9.0, 0.0, 14.0, 0.0, 0.0, 2.0, 3.0, 0.0, 19.0, 19.0, 214.0, 2.0, 53.0, 3.0, 3.0, 1.0, 0.0, 2.0, 5.0, 2.0, 1.0, 4.0, 9.0, 3.0, 93.0, 1.0, 1.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 19.0, 4.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 16.0, 1.0, 72.0, 0.0, 0.0, 56.0, 1.0, 6.0, 1.0, 0.0, 11.0, 0.0, 1.0, 1.0, 9.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 5.0, 0.0, 1.0, 2.0, 73.0, 1.0, 1.0, 0.0, 56.0, 1.0, 2.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 19.0, 12.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 5.0, 51.0, 0.0, 3.0, 1.0, 4.0, 3.0, 17.0, 0.0, 34.0, 59.0, 2.0, 1.0, 4.0, 0.0, 30.0, 887.0, 5.0, 0.0, 0.0, 14.0, 1.0, 13.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 3.0, 4.0, 0.0, 0.0, 6.0, 1.0, 0.0, 3.0, 3.0, 1.0, 4.0, 1.0, 0.0, 0.0, 54.0, 1.0, 1.0, 0.0, 7.0, 13.0, 3.0, 240.0, 1.0, 0.0, 25.0, 1.0, 7.0, 0.0, 2.0, 5.0, 0.0, 0.0, 2.0, 7.0, 1.0, 41.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 536.0, 2.0, 1.0, 15.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 0.0, 81.0, 0.0, 5.0, 0.0, 3.0, 0.0, 6.0, 0.0, 0.0, 2.0, 17.0, 0.0, 1.0, 114.0, 4.0, 1.0, 76.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 43.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 19.0, 18.0, 1.0, 4.0, 13.0, 215.0, 9.0, 218.0, 0.0, 14.0, 0.0, 0.0, 1.0, 0.0, 1.0, 8.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 582.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 4.0, 0.0, 0.0, 12.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 10.0, 4.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 3.0, 2.0, 0.0, 0.0, 76.0, 0.0, 1.0, 2.0, 1.0, 10.0, 0.0, 1.0, 98.0, 29.0, 0.0, 3.0, 1.0, 1.0, 1.0, 16.0, 1.0, 0.0, 4.0, 1.0, 1.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 104.0, 0.0, 4.0, 3.0, 0.0, 5.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 35.0, 17.0, 0.0, 45.0, 1.0, 3.0, 0.0, 294.0, 0.0, 6.0, 0.0, 639.0, 0.0, 2.0, 9.0, 10.0, 0.0, 12.0, 9.0, 0.0, 0.0, 0.0, 0.0, 7.0, 1.0, 9.0, 2.0, 7.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 14.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 322.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 6.0, 3.0, 1.0, 0.0, 4.0, 0.0, 21.0, 0.0, 0.0, 6.0, 2.0, 0.0, 1.0, 4.0, 33.0, 4.0, 50.0, 1.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 27.0, 14.0, 0.0, 0.0, 0.0, 21.0, 1.0, 0.0, 198.0, 3.0, 0.0, 0.0, 3.0, 42.0, 0.0, 105.0, 0.0, 3.0, 3.0, 0.0, 0.0, 37.0, 13.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 26.0, 1.0, 2.0, 10.0, 4.0, 0.0, 1.0, 0.0, 1.0, 1.0, 17.0, 0.0, 2.0, 2.0, 11.0, 2.0, 5.0, 2.0, 0.0, 0.0, 12.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 10.0, 1.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 2.0, 573.0, 6.0, 2.0, 5.0, 13.0, 3.0, 0.0, 15.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 533.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 17.0, 2.0, 1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 0.0, 22.0, 3.0, 1.0, 12.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 0.0, 6.0, 0.0, 45.0, 0.0, 0.0, 0.0, 0.0, 6.0, 22.0, 5.0, 3.0, 0.0, 2.0, 2.0, 1.0, 0.0, 73.0, 591.0, 10.0, 0.0, 1.0, 4.0, 3.0, 0.0, 90.0, 92.0, 38.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 11.0, 360.0, 0.0, 1.0, 3.0, 0.0, 2.0, 11.0, 80.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 33.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 4.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 4.0, 0.0, 2.0, 97.0, 4.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 7.0, 3.0, 12.0, 267.0, 0.0, 1.0, 0.0, 2.0, 5.0, 1.0, 6.0, 1.0, 2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 110.0, 0.0, 1.0, 4.0, 0.0, 1.0, 3.0, 585.0, 0.0, 1.0, 0.0, 1.0, 1.0, 12.0, 3.0, 1.0, 0.0, 2.0, 4.0, 2.0, 0.0, 3.0, 0.0, 0.0, 6.0, 2.0, 0.0, 1.0, 31.0, 81.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 270.0, 4.0, 3.0, 0.0, 2.0, 1.0, 271.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 14.0, 3.0, 4.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 3.0, 1.0, 0.0, 11.0, 21.0, 1.0, 1.0, 0.0, 9.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 35.0, 1.0, 1.0, 1.0, 85.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 12.0, 0.0, 3.0, 5.0, 0.0, 3.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 10.0, 5.0, 3.0, 5.0, 0.0, 129.0, 6.0, 68.0, 3.0, 0.0, 11.0, 2.0, 0.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.0, 10.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 5.0, 0.0, 3.0, 0.0, 0.0, 114.0, 5.0, 3.0, 0.0, 1.0, 13.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 29.0, 7.0, 50.0, 19.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 15.0, 0.0, 0.0, 6.0, 2.0, 1.0, 0.0, 488.0, 7.0, 1.0, 1.0, 10.0, 0.0, 0.0, 0.0, 7.0, 14.0, 3.0, 5.0, 2.0, 1.0, 16.0, 0.0, 12.0, 12.0, 0.0, 66.0, 0.0, 3.0, 3.0, 2.0, 26.0, 0.0, 0.0, 5.0, 12.0, 0.0, 11.0, 4.0, 21.0, 1.0, 2.0, 639.0, 2.0, 4.0, 0.0, 3.0, 16.0, 2.0, 0.0, 3.0, 5.0, 1.0, 0.0, 4.0, 2.0, 7.0, 2.0, 1.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 176.0, 555.0, 6.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 32.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 7.0, 0.0, 3.0, 0.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 27.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 10.0, 0.0, 0.0, 1.0, 5.0, 6.0, 11.0, 3.0, 2.0, 6.0, 1.0, 5.0, 29.0, 22.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 14.0, 2.0, 13.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 45.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 4.0, 4.0, 2.0, 9.0, 0.0, 1.0, 1.0, 111.0, 2.0, 0.0, 24.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 4.0, 38.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 86.0, 2.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 32.0, 87.0, 0.0, 6.0, 3.0, 15.0, 287.0, 123.0, 8.0, 11.0, 4.0, 1.0, 2.0, 0.0, 2.0, 0.0, 56.0, 0.0, 0.0, 3.0, 469.0, 15.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 906.0, 3.0, 0.0, 3.0, 0.0, 3.0, 2.0, 14.0, 2.0, 1.0, 0.0, 0.0, 0.0, 12.0, 1.0, 1.0, 0.0, 10.0, 0.0, 1272.0, 6.0, 0.0, 4.0, 0.0, 1.0, 0.0, 34.0, 4.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 1.0, 5.0, 0.0, 185.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 0.0, 1.0, 219.0, 0.0, 66.0]\n",
      "Mean Absolute Error: 3.85902688172043\n",
      "Mean Squared Error: 243.52775994623659\n",
      "Root Mean Squared Error: 15.605375995029297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = ml_input_value\n",
    "y = ml_output\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# print the results\n",
    "print('Predicted:', y_pred)\n",
    "print('Actual:', y_test)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [1.11300e+01 1.90000e-01 1.11500e+00 ... 1.97595e+02 1.08000e+00\n",
      " 4.48550e+01]\n",
      "Actual: [15.0, 0.0, 2.0, 1.0, 1.0, 0.0, 561.0, 0.0, 103.0, 49.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 606.0, 120.0, 0.0, 0.0, 524.0, 0.0, 28.0, 4.0, 164.0, 6.0, 0.0, 9.0, 0.0, 1.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 12.0, 21.0, 1.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 0.0, 3.0, 0.0, 1.0, 33.0, 0.0, 12.0, 0.0, 3.0, 3.0, 7.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 1.0, 16.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 27.0, 204.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 10.0, 1.0, 35.0, 2.0, 1.0, 18.0, 3.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 4.0, 6.0, 0.0, 64.0, 6.0, 6.0, 0.0, 0.0, 1.0, 119.0, 0.0, 13.0, 25.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 24.0, 139.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 7.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 3.0, 4.0, 2.0, 3.0, 162.0, 38.0, 0.0, 0.0, 0.0, 4.0, 1.0, 10.0, 0.0, 0.0, 27.0, 10.0, 0.0, 1.0, 58.0, 3.0, 4.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 762.0, 3.0, 0.0, 0.0, 1.0, 18.0, 55.0, 206.0, 3.0, 4.0, 0.0, 17.0, 0.0, 0.0, 0.0, 5.0, 3.0, 3.0, 0.0, 1.0, 34.0, 0.0, 2.0, 2.0, 0.0, 15.0, 1.0, 87.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 3.0, 192.0, 47.0, 1.0, 22.0, 1.0, 10.0, 0.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 603.0, 7.0, 3.0, 3.0, 2.0, 287.0, 61.0, 1.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 0.0, 0.0, 566.0, 0.0, 2.0, 358.0, 0.0, 3.0, 20.0, 0.0, 2.0, 5.0, 2.0, 2.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 7.0, 0.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 5.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 11.0, 6.0, 33.0, 6.0, 1.0, 0.0, 9.0, 2.0, 0.0, 15.0, 2.0, 4.0, 1.0, 464.0, 8.0, 1.0, 30.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 6.0, 3.0, 458.0, 0.0, 10.0, 1.0, 0.0, 6.0, 1.0, 0.0, 140.0, 0.0, 13.0, 3.0, 6.0, 0.0, 4.0, 1.0, 2.0, 34.0, 3.0, 10.0, 0.0, 1.0, 0.0, 55.0, 1.0, 0.0, 0.0, 4.0, 118.0, 3.0, 299.0, 0.0, 9.0, 3.0, 0.0, 4.0, 7.0, 1.0, 2.0, 2.0, 5.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 2.0, 0.0, 0.0, 3.0, 9.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 4.0, 5.0, 0.0, 1.0, 477.0, 0.0, 8.0, 1.0, 2.0, 3.0, 0.0, 0.0, 3.0, 0.0, 3.0, 6.0, 1.0, 0.0, 0.0, 77.0, 0.0, 0.0, 0.0, 5.0, 448.0, 0.0, 0.0, 11.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 12.0, 6.0, 0.0, 6.0, 5.0, 0.0, 8.0, 20.0, 1.0, 1.0, 60.0, 12.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 16.0, 1.0, 1.0, 1.0, 1.0, 49.0, 0.0, 0.0, 0.0, 576.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 2.0, 3.0, 11.0, 1.0, 6.0, 1.0, 234.0, 3.0, 4.0, 0.0, 0.0, 6.0, 4.0, 0.0, 25.0, 0.0, 5.0, 48.0, 6.0, 624.0, 0.0, 1.0, 113.0, 0.0, 3.0, 5.0, 1.0, 3.0, 2.0, 4.0, 0.0, 0.0, 1.0, 21.0, 1.0, 0.0, 8.0, 3.0, 15.0, 0.0, 4.0, 0.0, 10.0, 0.0, 30.0, 2.0, 0.0, 249.0, 262.0, 86.0, 4.0, 2.0, 0.0, 6.0, 1.0, 1.0, 0.0, 2.0, 289.0, 20.0, 0.0, 5.0, 0.0, 458.0, 0.0, 560.0, 2.0, 7.0, 6.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 1.0, 9.0, 0.0, 3.0, 7.0, 0.0, 1.0, 1.0, 2.0, 119.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 33.0, 57.0, 3.0, 3.0, 2.0, 1.0, 10.0, 4.0, 5.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 6.0, 0.0, 1.0, 0.0, 16.0, 0.0, 86.0, 0.0, 0.0, 1.0, 36.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 4.0, 0.0, 0.0, 6.0, 1.0, 19.0, 10.0, 0.0, 7.0, 6.0, 0.0, 5.0, 0.0, 0.0, 12.0, 493.0, 27.0, 1.0, 0.0, 104.0, 0.0, 3.0, 0.0, 13.0, 2.0, 2.0, 66.0, 0.0, 29.0, 1.0, 2.0, 0.0, 1.0, 5.0, 1.0, 1.0, 0.0, 26.0, 2.0, 0.0, 5.0, 1.0, 0.0, 0.0, 1.0, 0.0, 87.0, 2.0, 2.0, 4.0, 1.0, 0.0, 2.0, 4.0, 0.0, 18.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 310.0, 0.0, 3.0, 1.0, 2.0, 0.0, 3.0, 31.0, 2.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 15.0, 1.0, 20.0, 10.0, 0.0, 0.0, 1.0, 9.0, 0.0, 14.0, 0.0, 0.0, 2.0, 3.0, 0.0, 19.0, 19.0, 214.0, 2.0, 53.0, 3.0, 3.0, 1.0, 0.0, 2.0, 5.0, 2.0, 1.0, 4.0, 9.0, 3.0, 93.0, 1.0, 1.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 19.0, 4.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 16.0, 1.0, 72.0, 0.0, 0.0, 56.0, 1.0, 6.0, 1.0, 0.0, 11.0, 0.0, 1.0, 1.0, 9.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 5.0, 0.0, 1.0, 2.0, 73.0, 1.0, 1.0, 0.0, 56.0, 1.0, 2.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 19.0, 12.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 5.0, 51.0, 0.0, 3.0, 1.0, 4.0, 3.0, 17.0, 0.0, 34.0, 59.0, 2.0, 1.0, 4.0, 0.0, 30.0, 887.0, 5.0, 0.0, 0.0, 14.0, 1.0, 13.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 3.0, 4.0, 0.0, 0.0, 6.0, 1.0, 0.0, 3.0, 3.0, 1.0, 4.0, 1.0, 0.0, 0.0, 54.0, 1.0, 1.0, 0.0, 7.0, 13.0, 3.0, 240.0, 1.0, 0.0, 25.0, 1.0, 7.0, 0.0, 2.0, 5.0, 0.0, 0.0, 2.0, 7.0, 1.0, 41.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 536.0, 2.0, 1.0, 15.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 0.0, 81.0, 0.0, 5.0, 0.0, 3.0, 0.0, 6.0, 0.0, 0.0, 2.0, 17.0, 0.0, 1.0, 114.0, 4.0, 1.0, 76.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 43.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 19.0, 18.0, 1.0, 4.0, 13.0, 215.0, 9.0, 218.0, 0.0, 14.0, 0.0, 0.0, 1.0, 0.0, 1.0, 8.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 582.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 4.0, 0.0, 0.0, 12.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 10.0, 4.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 3.0, 2.0, 0.0, 0.0, 76.0, 0.0, 1.0, 2.0, 1.0, 10.0, 0.0, 1.0, 98.0, 29.0, 0.0, 3.0, 1.0, 1.0, 1.0, 16.0, 1.0, 0.0, 4.0, 1.0, 1.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 104.0, 0.0, 4.0, 3.0, 0.0, 5.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 35.0, 17.0, 0.0, 45.0, 1.0, 3.0, 0.0, 294.0, 0.0, 6.0, 0.0, 639.0, 0.0, 2.0, 9.0, 10.0, 0.0, 12.0, 9.0, 0.0, 0.0, 0.0, 0.0, 7.0, 1.0, 9.0, 2.0, 7.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 14.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 322.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 6.0, 3.0, 1.0, 0.0, 4.0, 0.0, 21.0, 0.0, 0.0, 6.0, 2.0, 0.0, 1.0, 4.0, 33.0, 4.0, 50.0, 1.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 27.0, 14.0, 0.0, 0.0, 0.0, 21.0, 1.0, 0.0, 198.0, 3.0, 0.0, 0.0, 3.0, 42.0, 0.0, 105.0, 0.0, 3.0, 3.0, 0.0, 0.0, 37.0, 13.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 26.0, 1.0, 2.0, 10.0, 4.0, 0.0, 1.0, 0.0, 1.0, 1.0, 17.0, 0.0, 2.0, 2.0, 11.0, 2.0, 5.0, 2.0, 0.0, 0.0, 12.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 10.0, 1.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 2.0, 573.0, 6.0, 2.0, 5.0, 13.0, 3.0, 0.0, 15.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 533.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 17.0, 2.0, 1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 0.0, 22.0, 3.0, 1.0, 12.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 0.0, 6.0, 0.0, 45.0, 0.0, 0.0, 0.0, 0.0, 6.0, 22.0, 5.0, 3.0, 0.0, 2.0, 2.0, 1.0, 0.0, 73.0, 591.0, 10.0, 0.0, 1.0, 4.0, 3.0, 0.0, 90.0, 92.0, 38.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 11.0, 360.0, 0.0, 1.0, 3.0, 0.0, 2.0, 11.0, 80.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 33.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 4.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 4.0, 0.0, 2.0, 97.0, 4.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 7.0, 3.0, 12.0, 267.0, 0.0, 1.0, 0.0, 2.0, 5.0, 1.0, 6.0, 1.0, 2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 110.0, 0.0, 1.0, 4.0, 0.0, 1.0, 3.0, 585.0, 0.0, 1.0, 0.0, 1.0, 1.0, 12.0, 3.0, 1.0, 0.0, 2.0, 4.0, 2.0, 0.0, 3.0, 0.0, 0.0, 6.0, 2.0, 0.0, 1.0, 31.0, 81.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 270.0, 4.0, 3.0, 0.0, 2.0, 1.0, 271.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 14.0, 3.0, 4.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 3.0, 1.0, 0.0, 11.0, 21.0, 1.0, 1.0, 0.0, 9.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 35.0, 1.0, 1.0, 1.0, 85.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 12.0, 0.0, 3.0, 5.0, 0.0, 3.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 10.0, 5.0, 3.0, 5.0, 0.0, 129.0, 6.0, 68.0, 3.0, 0.0, 11.0, 2.0, 0.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.0, 10.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 5.0, 0.0, 3.0, 0.0, 0.0, 114.0, 5.0, 3.0, 0.0, 1.0, 13.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 29.0, 7.0, 50.0, 19.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 15.0, 0.0, 0.0, 6.0, 2.0, 1.0, 0.0, 488.0, 7.0, 1.0, 1.0, 10.0, 0.0, 0.0, 0.0, 7.0, 14.0, 3.0, 5.0, 2.0, 1.0, 16.0, 0.0, 12.0, 12.0, 0.0, 66.0, 0.0, 3.0, 3.0, 2.0, 26.0, 0.0, 0.0, 5.0, 12.0, 0.0, 11.0, 4.0, 21.0, 1.0, 2.0, 639.0, 2.0, 4.0, 0.0, 3.0, 16.0, 2.0, 0.0, 3.0, 5.0, 1.0, 0.0, 4.0, 2.0, 7.0, 2.0, 1.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 176.0, 555.0, 6.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 32.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 7.0, 0.0, 3.0, 0.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 27.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 10.0, 0.0, 0.0, 1.0, 5.0, 6.0, 11.0, 3.0, 2.0, 6.0, 1.0, 5.0, 29.0, 22.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 14.0, 2.0, 13.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 45.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 4.0, 4.0, 2.0, 9.0, 0.0, 1.0, 1.0, 111.0, 2.0, 0.0, 24.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 4.0, 38.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 86.0, 2.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 32.0, 87.0, 0.0, 6.0, 3.0, 15.0, 287.0, 123.0, 8.0, 11.0, 4.0, 1.0, 2.0, 0.0, 2.0, 0.0, 56.0, 0.0, 0.0, 3.0, 469.0, 15.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 906.0, 3.0, 0.0, 3.0, 0.0, 3.0, 2.0, 14.0, 2.0, 1.0, 0.0, 0.0, 0.0, 12.0, 1.0, 1.0, 0.0, 10.0, 0.0, 1272.0, 6.0, 0.0, 4.0, 0.0, 1.0, 0.0, 34.0, 4.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 1.0, 5.0, 0.0, 185.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 0.0, 1.0, 219.0, 0.0, 66.0]\n",
      "Mean Absolute Error: 3.7999274193548387\n",
      "Mean Squared Error: 235.22317856182792\n",
      "Root Mean Squared Error: 15.336987271358998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = ml_input_value\n",
    "y = ml_output\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# print the results\n",
    "print('Predicted:', y_pred)\n",
    "print('Actual:', y_test)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [ 11.41   0.2    0.93 ... 198.33   1.96  40.9 ]\n",
      "Actual: [15.0, 0.0, 2.0, 1.0, 1.0, 0.0, 561.0, 0.0, 103.0, 49.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 606.0, 120.0, 0.0, 0.0, 524.0, 0.0, 28.0, 4.0, 164.0, 6.0, 0.0, 9.0, 0.0, 1.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 12.0, 21.0, 1.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 0.0, 3.0, 0.0, 1.0, 33.0, 0.0, 12.0, 0.0, 3.0, 3.0, 7.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 1.0, 16.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 27.0, 204.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 10.0, 1.0, 35.0, 2.0, 1.0, 18.0, 3.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 4.0, 6.0, 0.0, 64.0, 6.0, 6.0, 0.0, 0.0, 1.0, 119.0, 0.0, 13.0, 25.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 24.0, 139.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 7.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 3.0, 4.0, 2.0, 3.0, 162.0, 38.0, 0.0, 0.0, 0.0, 4.0, 1.0, 10.0, 0.0, 0.0, 27.0, 10.0, 0.0, 1.0, 58.0, 3.0, 4.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 762.0, 3.0, 0.0, 0.0, 1.0, 18.0, 55.0, 206.0, 3.0, 4.0, 0.0, 17.0, 0.0, 0.0, 0.0, 5.0, 3.0, 3.0, 0.0, 1.0, 34.0, 0.0, 2.0, 2.0, 0.0, 15.0, 1.0, 87.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 3.0, 192.0, 47.0, 1.0, 22.0, 1.0, 10.0, 0.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 603.0, 7.0, 3.0, 3.0, 2.0, 287.0, 61.0, 1.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 0.0, 0.0, 566.0, 0.0, 2.0, 358.0, 0.0, 3.0, 20.0, 0.0, 2.0, 5.0, 2.0, 2.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 7.0, 0.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 5.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 11.0, 6.0, 33.0, 6.0, 1.0, 0.0, 9.0, 2.0, 0.0, 15.0, 2.0, 4.0, 1.0, 464.0, 8.0, 1.0, 30.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 6.0, 3.0, 458.0, 0.0, 10.0, 1.0, 0.0, 6.0, 1.0, 0.0, 140.0, 0.0, 13.0, 3.0, 6.0, 0.0, 4.0, 1.0, 2.0, 34.0, 3.0, 10.0, 0.0, 1.0, 0.0, 55.0, 1.0, 0.0, 0.0, 4.0, 118.0, 3.0, 299.0, 0.0, 9.0, 3.0, 0.0, 4.0, 7.0, 1.0, 2.0, 2.0, 5.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 2.0, 0.0, 0.0, 3.0, 9.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 4.0, 5.0, 0.0, 1.0, 477.0, 0.0, 8.0, 1.0, 2.0, 3.0, 0.0, 0.0, 3.0, 0.0, 3.0, 6.0, 1.0, 0.0, 0.0, 77.0, 0.0, 0.0, 0.0, 5.0, 448.0, 0.0, 0.0, 11.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 12.0, 6.0, 0.0, 6.0, 5.0, 0.0, 8.0, 20.0, 1.0, 1.0, 60.0, 12.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 16.0, 1.0, 1.0, 1.0, 1.0, 49.0, 0.0, 0.0, 0.0, 576.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 2.0, 3.0, 11.0, 1.0, 6.0, 1.0, 234.0, 3.0, 4.0, 0.0, 0.0, 6.0, 4.0, 0.0, 25.0, 0.0, 5.0, 48.0, 6.0, 624.0, 0.0, 1.0, 113.0, 0.0, 3.0, 5.0, 1.0, 3.0, 2.0, 4.0, 0.0, 0.0, 1.0, 21.0, 1.0, 0.0, 8.0, 3.0, 15.0, 0.0, 4.0, 0.0, 10.0, 0.0, 30.0, 2.0, 0.0, 249.0, 262.0, 86.0, 4.0, 2.0, 0.0, 6.0, 1.0, 1.0, 0.0, 2.0, 289.0, 20.0, 0.0, 5.0, 0.0, 458.0, 0.0, 560.0, 2.0, 7.0, 6.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 1.0, 9.0, 0.0, 3.0, 7.0, 0.0, 1.0, 1.0, 2.0, 119.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 33.0, 57.0, 3.0, 3.0, 2.0, 1.0, 10.0, 4.0, 5.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 6.0, 0.0, 1.0, 0.0, 16.0, 0.0, 86.0, 0.0, 0.0, 1.0, 36.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 4.0, 0.0, 0.0, 6.0, 1.0, 19.0, 10.0, 0.0, 7.0, 6.0, 0.0, 5.0, 0.0, 0.0, 12.0, 493.0, 27.0, 1.0, 0.0, 104.0, 0.0, 3.0, 0.0, 13.0, 2.0, 2.0, 66.0, 0.0, 29.0, 1.0, 2.0, 0.0, 1.0, 5.0, 1.0, 1.0, 0.0, 26.0, 2.0, 0.0, 5.0, 1.0, 0.0, 0.0, 1.0, 0.0, 87.0, 2.0, 2.0, 4.0, 1.0, 0.0, 2.0, 4.0, 0.0, 18.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 310.0, 0.0, 3.0, 1.0, 2.0, 0.0, 3.0, 31.0, 2.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 15.0, 1.0, 20.0, 10.0, 0.0, 0.0, 1.0, 9.0, 0.0, 14.0, 0.0, 0.0, 2.0, 3.0, 0.0, 19.0, 19.0, 214.0, 2.0, 53.0, 3.0, 3.0, 1.0, 0.0, 2.0, 5.0, 2.0, 1.0, 4.0, 9.0, 3.0, 93.0, 1.0, 1.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 19.0, 4.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 16.0, 1.0, 72.0, 0.0, 0.0, 56.0, 1.0, 6.0, 1.0, 0.0, 11.0, 0.0, 1.0, 1.0, 9.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 5.0, 0.0, 1.0, 2.0, 73.0, 1.0, 1.0, 0.0, 56.0, 1.0, 2.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 19.0, 12.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 5.0, 51.0, 0.0, 3.0, 1.0, 4.0, 3.0, 17.0, 0.0, 34.0, 59.0, 2.0, 1.0, 4.0, 0.0, 30.0, 887.0, 5.0, 0.0, 0.0, 14.0, 1.0, 13.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 3.0, 4.0, 0.0, 0.0, 6.0, 1.0, 0.0, 3.0, 3.0, 1.0, 4.0, 1.0, 0.0, 0.0, 54.0, 1.0, 1.0, 0.0, 7.0, 13.0, 3.0, 240.0, 1.0, 0.0, 25.0, 1.0, 7.0, 0.0, 2.0, 5.0, 0.0, 0.0, 2.0, 7.0, 1.0, 41.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 536.0, 2.0, 1.0, 15.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 0.0, 81.0, 0.0, 5.0, 0.0, 3.0, 0.0, 6.0, 0.0, 0.0, 2.0, 17.0, 0.0, 1.0, 114.0, 4.0, 1.0, 76.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 43.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 19.0, 18.0, 1.0, 4.0, 13.0, 215.0, 9.0, 218.0, 0.0, 14.0, 0.0, 0.0, 1.0, 0.0, 1.0, 8.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 582.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 4.0, 0.0, 0.0, 12.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 10.0, 4.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 3.0, 2.0, 0.0, 0.0, 76.0, 0.0, 1.0, 2.0, 1.0, 10.0, 0.0, 1.0, 98.0, 29.0, 0.0, 3.0, 1.0, 1.0, 1.0, 16.0, 1.0, 0.0, 4.0, 1.0, 1.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 104.0, 0.0, 4.0, 3.0, 0.0, 5.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 35.0, 17.0, 0.0, 45.0, 1.0, 3.0, 0.0, 294.0, 0.0, 6.0, 0.0, 639.0, 0.0, 2.0, 9.0, 10.0, 0.0, 12.0, 9.0, 0.0, 0.0, 0.0, 0.0, 7.0, 1.0, 9.0, 2.0, 7.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 14.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 322.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 6.0, 3.0, 1.0, 0.0, 4.0, 0.0, 21.0, 0.0, 0.0, 6.0, 2.0, 0.0, 1.0, 4.0, 33.0, 4.0, 50.0, 1.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 27.0, 14.0, 0.0, 0.0, 0.0, 21.0, 1.0, 0.0, 198.0, 3.0, 0.0, 0.0, 3.0, 42.0, 0.0, 105.0, 0.0, 3.0, 3.0, 0.0, 0.0, 37.0, 13.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 26.0, 1.0, 2.0, 10.0, 4.0, 0.0, 1.0, 0.0, 1.0, 1.0, 17.0, 0.0, 2.0, 2.0, 11.0, 2.0, 5.0, 2.0, 0.0, 0.0, 12.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 10.0, 1.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 2.0, 573.0, 6.0, 2.0, 5.0, 13.0, 3.0, 0.0, 15.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 533.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 17.0, 2.0, 1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 0.0, 22.0, 3.0, 1.0, 12.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 0.0, 6.0, 0.0, 45.0, 0.0, 0.0, 0.0, 0.0, 6.0, 22.0, 5.0, 3.0, 0.0, 2.0, 2.0, 1.0, 0.0, 73.0, 591.0, 10.0, 0.0, 1.0, 4.0, 3.0, 0.0, 90.0, 92.0, 38.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 11.0, 360.0, 0.0, 1.0, 3.0, 0.0, 2.0, 11.0, 80.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 33.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 4.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 4.0, 0.0, 2.0, 97.0, 4.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 7.0, 3.0, 12.0, 267.0, 0.0, 1.0, 0.0, 2.0, 5.0, 1.0, 6.0, 1.0, 2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 110.0, 0.0, 1.0, 4.0, 0.0, 1.0, 3.0, 585.0, 0.0, 1.0, 0.0, 1.0, 1.0, 12.0, 3.0, 1.0, 0.0, 2.0, 4.0, 2.0, 0.0, 3.0, 0.0, 0.0, 6.0, 2.0, 0.0, 1.0, 31.0, 81.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 270.0, 4.0, 3.0, 0.0, 2.0, 1.0, 271.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 14.0, 3.0, 4.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 3.0, 1.0, 0.0, 11.0, 21.0, 1.0, 1.0, 0.0, 9.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 35.0, 1.0, 1.0, 1.0, 85.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 12.0, 0.0, 3.0, 5.0, 0.0, 3.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 10.0, 5.0, 3.0, 5.0, 0.0, 129.0, 6.0, 68.0, 3.0, 0.0, 11.0, 2.0, 0.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.0, 10.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 5.0, 0.0, 3.0, 0.0, 0.0, 114.0, 5.0, 3.0, 0.0, 1.0, 13.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 29.0, 7.0, 50.0, 19.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 15.0, 0.0, 0.0, 6.0, 2.0, 1.0, 0.0, 488.0, 7.0, 1.0, 1.0, 10.0, 0.0, 0.0, 0.0, 7.0, 14.0, 3.0, 5.0, 2.0, 1.0, 16.0, 0.0, 12.0, 12.0, 0.0, 66.0, 0.0, 3.0, 3.0, 2.0, 26.0, 0.0, 0.0, 5.0, 12.0, 0.0, 11.0, 4.0, 21.0, 1.0, 2.0, 639.0, 2.0, 4.0, 0.0, 3.0, 16.0, 2.0, 0.0, 3.0, 5.0, 1.0, 0.0, 4.0, 2.0, 7.0, 2.0, 1.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 176.0, 555.0, 6.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 32.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 7.0, 0.0, 3.0, 0.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 27.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 10.0, 0.0, 0.0, 1.0, 5.0, 6.0, 11.0, 3.0, 2.0, 6.0, 1.0, 5.0, 29.0, 22.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 14.0, 2.0, 13.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 45.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 4.0, 4.0, 2.0, 9.0, 0.0, 1.0, 1.0, 111.0, 2.0, 0.0, 24.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 4.0, 38.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 86.0, 2.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 32.0, 87.0, 0.0, 6.0, 3.0, 15.0, 287.0, 123.0, 8.0, 11.0, 4.0, 1.0, 2.0, 0.0, 2.0, 0.0, 56.0, 0.0, 0.0, 3.0, 469.0, 15.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 906.0, 3.0, 0.0, 3.0, 0.0, 3.0, 2.0, 14.0, 2.0, 1.0, 0.0, 0.0, 0.0, 12.0, 1.0, 1.0, 0.0, 10.0, 0.0, 1272.0, 6.0, 0.0, 4.0, 0.0, 1.0, 0.0, 34.0, 4.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 1.0, 5.0, 0.0, 185.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 0.0, 1.0, 219.0, 0.0, 66.0]\n",
      "Mean Absolute Error: 4.3851056624948495\n",
      "Mean Squared Error: 335.19187304703445\n",
      "Root Mean Squared Error: 18.308246039613802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = ml_input_value\n",
    "y = ml_output\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "sel = SelectFromModel(model)\n",
    "X_trans = sel.fit_transform(X_train, y_train)\n",
    "\n",
    "model.fit(X_trans, y_train)\n",
    "\n",
    "X_test_trans = sel.transform(X_test)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test_trans)\n",
    "\n",
    "# print the results\n",
    "print('Predicted:', y_pred)\n",
    "print('Actual:', y_test)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "X = ml_input_value\n",
    "y = ml_output\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# print the results\n",
    "print('Predicted:', y_pred)\n",
    "print('Actual:', y_test)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_input_value = [e[\"views\"].tolist() + list(np.empty(30- len(e[\"views\"].tolist()))) + [float(pd.to_datetime(e.iloc[0][\"date\"], format='%Y%m%d%H').dayofweek)] for e in ml_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13618.0,\n",
       " 10.0,\n",
       " 73.0,\n",
       " 1780.0,\n",
       " 1.0,\n",
       " 115.0,\n",
       " 1125.0,\n",
       " 237.0,\n",
       " 4323.0,\n",
       " 131.0,\n",
       " 3.0,\n",
       " 7.0,\n",
       " 39.0,\n",
       " 2052.0,\n",
       " 5.0,\n",
       " 38.0,\n",
       " 404.0,\n",
       " 50.0,\n",
       " 4.0,\n",
       " 418.0,\n",
       " 229.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 126.0,\n",
       " 13.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 218.0,\n",
       " 0.0,\n",
       " 29.0,\n",
       " 2.0]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ml_input_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SeipelMa\\Code\\vscode-workspace\\DataScience\\DataflowAnalysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:521: RuntimeWarning: overflow encountered in cast\n",
      "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[198], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m DecisionTreeRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# make predictions\u001b[39;00m\n\u001b[0;32m     15\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\SeipelMa\\Code\\vscode-workspace\\DataScience\\DataflowAnalysis\\.venv\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SeipelMa\\Code\\vscode-workspace\\DataScience\\DataflowAnalysis\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1377\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \n\u001b[0;32m   1351\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\SeipelMa\\Code\\vscode-workspace\\DataScience\\DataflowAnalysis\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:257\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    251\u001b[0m check_y_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    252\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    253\u001b[0m     X, y, validate_separately\u001b[38;5;241m=\u001b[39m(check_X_params, check_y_params)\n\u001b[0;32m    254\u001b[0m )\n\u001b[0;32m    256\u001b[0m missing_values_in_feature_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 257\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_missing_values_in_feature_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m    260\u001b[0m     X\u001b[38;5;241m.\u001b[39msort_indices()\n",
      "File \u001b[1;32mc:\\Users\\SeipelMa\\Code\\vscode-workspace\\DataScience\\DataflowAnalysis\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:222\u001b[0m, in \u001b[0;36mBaseDecisionTree._compute_missing_values_in_feature_mask\u001b[1;34m(self, X, estimator_name)\u001b[0m\n\u001b[0;32m    218\u001b[0m     overall_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(X)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(overall_sum):\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# Raise a ValueError in case of the presence of an infinite element.\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcommon_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# If the sum is not nan, then there are no missing values\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(overall_sum):\n",
      "File \u001b[1;32mc:\\Users\\SeipelMa\\Code\\vscode-workspace\\DataScience\\DataflowAnalysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m     )\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X = ml_input_value\n",
    "y = ml_output\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# print the results\n",
    "print('Predicted:', y_pred)\n",
    "print('Actual:', y_test)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
